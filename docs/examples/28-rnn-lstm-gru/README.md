# Recurrent Neural Network Layers

Demonstrates RNN, LSTM, and GRU layers for sequence modeling tasks.

## Deepbox Modules Used

| Module            | Features Used      |
| ----------------- | ------------------ |
| `deepbox/ndarray` | tensor, GradTensor |
| `deepbox/nn`      | RNN, LSTM, GRU     |

## Usage

```bash
npm run example:28
```

## Output

- Console output showing sequence processing with different recurrent architectures
- Parameter count comparison between RNN, LSTM, and GRU
